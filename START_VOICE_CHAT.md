# Quick Start Guide: Voice Chat

## Prerequisites

**1. Install FFmpeg (if not already installed):**
```bash
# Ubuntu/Debian
sudo apt-get install ffmpeg

# macOS
brew install ffmpeg

# Windows
# Download from https://ffmpeg.org/download.html
```

**2. Install Python dependencies:**
```bash
cd services/ai_backend
pip install aiohttp aiohttp-cors openai-whisper google-cloud-texttospeech
```

**3. Configure API Keys:**
Edit `services/ai_backend/config.yaml` and add your OpenAI API key:
```yaml
llm:
  api_keys:
    openai: "your-openai-api-key-here"
```

## Starting the Services

You need to run these servers (each in a separate terminal/window):

### Terminal 1: AI Backend (gRPC - port 50051)
```bash
cd services/ai_backend
python server.py
```
**Look for:** `‚úì AI Servicer initialized` and `Server started on port 50051`

### Terminal 2: Voice Server (WebSocket - port 8080)
```bash
cd services/ai_backend
python voice_server.py
```
**Look for:** `Voice WebSocket server started on port 8080`

### Terminal 3: Web Backend (port 5000)
```bash
cd services/backend
python app.py
```
**Look for:** `Running on http://0.0.0.0:5000`

### Terminal 4: Frontend (port 8000)
```bash
cd services/frontend
python -m http.server 8000
```
**Look for:** `Serving HTTP on 0.0.0.0 port 8000`

## Using Voice Chat

1. Open browser: http://localhost:8000/dashboard/
2. Click **"Voice Chat"** button
3. Wait for **green "Connected"** status dot
4. Click the **microphone button** to start
5. **Speak clearly** and wait **1.5 seconds** after finishing
6. Watch for console message: `üõë VAD: Speech ENDED`
7. Wait **2-4 seconds** for AI response

## Troubleshooting

### Port Already in Use

**Error:** `Failed to bind to address [::]:50051`
**Solution:** Server is already running! Just skip starting that server.

### FFmpeg Not Found

**Error:** `FFmpeg not found`
**Solution:** Install FFmpeg using the commands above

### Transcription Errors

**Error:** `Error code: 400 - Invalid file format`
**Solution:** Make sure FFmpeg is installed and working

### No Response / Takes Too Long

**Checklist:**
- ‚úÖ All 4 servers running?
- ‚úÖ AI backend shows "Connected" (green dot)?
- ‚úÖ VAD detected speech end? (check console for `üõë VAD: Speech ENDED`)
- ‚úÖ OpenAI API key is valid?
- ‚úÖ Speaking clearly and pausing 1.5s after finishing?

### Adjust VAD Settings

If voice detection isn't working well:

**Settings Panel (gear icon):**
- **Voice Detection Sensitivity**:
  - 0.10 = picks up quieter speech
  - 0.15 = default (works for most)
  - 0.25 = needs louder speech

- **Pause Duration**:
  - 1000ms = responds faster (may cut you off)
  - 1500ms = default (good balance)
  - 2000ms = waits longer (better for slow speakers)

## Performance

- **Current:** 2-4 seconds response time (60% faster than before!)
- **Breakdown:**
  - VAD silence detection: 1.5s
  - Audio transcription: 0.5-1s
  - AI response streaming: 0.5-1s
  - TTS synthesis: 0.5-1s

## Architecture

```
Browser (VAD) ‚Üí WebSocket (8080) ‚Üí Voice Server
                                        ‚Üì
                                   Transcription
                                        ‚Üì
                                gRPC AI Backend (50051)
                                        ‚Üì
                                  Streaming Response
                                        ‚Üì
                                    TTS per Sentence
                                        ‚Üì
                    WebSocket ‚Üê Audio Chunks ‚Üê Voice Server
                        ‚Üì
                  Browser Playback
```

## Next Steps

For even lower latency (<500ms-2s), future optimizations:
1. Streaming ASR (transcribe while speaking)
2. Token-level TTS (not sentence-level)
3. Direct codec support (eliminate FFmpeg)
4. Interrupt capability
